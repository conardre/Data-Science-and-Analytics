{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Exercise with `R`\n",
    "\n",
    "There is still a lot to learn about machine learning, and it is important to recognize that we have barely started to scrape the surface of it. There are many things we could do to refine our model that we didn't touch on in this module (don't worry, these will be covered throughout your curriculum), such as data transformation, elegant methods for automated feature selection, as well as unsupervised learning.\n",
    "\n",
    "For these exercises, we ask you to only complete **ONE** of the exercise notebooks, either `Python` or `R`. We will be asking you to predict wine quality using both Decision Tree and Naïve Bayes. Your exercises will serve as a sort-of extended practice in which you are free to try and refine the model however you see fit, but we do ask you to use both Decision Tree and Naïve Bayes.\n",
    "\n",
    "The questions will guide you a bit, but if you want to experiment or you find, through data exploration, a model that is better, feel free to do so. If you go this route, leave comments in the code justifying why you did what you did."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(tree)\n",
    "library(ggplot2)\n",
    "library(e1071)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in the Data\n",
    "\n",
    "Today we will be using the Red Wine Quality data. The target variable is numeric, so we are going to discretize it a bit before we get to the activities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A data.frame: 6 × 12</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>fixed.acidity</th><th scope=col>volatile.acidity</th><th scope=col>citric.acid</th><th scope=col>residual.sugar</th><th scope=col>chlorides</th><th scope=col>free.sulfur.dioxide</th><th scope=col>total.sulfur.dioxide</th><th scope=col>density</th><th scope=col>pH</th><th scope=col>sulphates</th><th scope=col>alcohol</th><th scope=col>quality</th></tr>\n",
       "\t<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;int&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td> 7.4</td><td>0.70</td><td>0.00</td><td>1.9</td><td>0.076</td><td>11</td><td>34</td><td>0.9978</td><td>3.51</td><td>0.56</td><td>9.4</td><td>5</td></tr>\n",
       "\t<tr><td> 7.8</td><td>0.88</td><td>0.00</td><td>2.6</td><td>0.098</td><td>25</td><td>67</td><td>0.9968</td><td>3.20</td><td>0.68</td><td>9.8</td><td>5</td></tr>\n",
       "\t<tr><td> 7.8</td><td>0.76</td><td>0.04</td><td>2.3</td><td>0.092</td><td>15</td><td>54</td><td>0.9970</td><td>3.26</td><td>0.65</td><td>9.8</td><td>5</td></tr>\n",
       "\t<tr><td>11.2</td><td>0.28</td><td>0.56</td><td>1.9</td><td>0.075</td><td>17</td><td>60</td><td>0.9980</td><td>3.16</td><td>0.58</td><td>9.8</td><td>6</td></tr>\n",
       "\t<tr><td> 7.4</td><td>0.70</td><td>0.00</td><td>1.9</td><td>0.076</td><td>11</td><td>34</td><td>0.9978</td><td>3.51</td><td>0.56</td><td>9.4</td><td>5</td></tr>\n",
       "\t<tr><td> 7.4</td><td>0.66</td><td>0.00</td><td>1.8</td><td>0.075</td><td>13</td><td>40</td><td>0.9978</td><td>3.51</td><td>0.56</td><td>9.4</td><td>5</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 6 × 12\n",
       "\\begin{tabular}{r|llllllllllll}\n",
       " fixed.acidity & volatile.acidity & citric.acid & residual.sugar & chlorides & free.sulfur.dioxide & total.sulfur.dioxide & density & pH & sulphates & alcohol & quality\\\\\n",
       " <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <int>\\\\\n",
       "\\hline\n",
       "\t  7.4 & 0.70 & 0.00 & 1.9 & 0.076 & 11 & 34 & 0.9978 & 3.51 & 0.56 & 9.4 & 5\\\\\n",
       "\t  7.8 & 0.88 & 0.00 & 2.6 & 0.098 & 25 & 67 & 0.9968 & 3.20 & 0.68 & 9.8 & 5\\\\\n",
       "\t  7.8 & 0.76 & 0.04 & 2.3 & 0.092 & 15 & 54 & 0.9970 & 3.26 & 0.65 & 9.8 & 5\\\\\n",
       "\t 11.2 & 0.28 & 0.56 & 1.9 & 0.075 & 17 & 60 & 0.9980 & 3.16 & 0.58 & 9.8 & 6\\\\\n",
       "\t  7.4 & 0.70 & 0.00 & 1.9 & 0.076 & 11 & 34 & 0.9978 & 3.51 & 0.56 & 9.4 & 5\\\\\n",
       "\t  7.4 & 0.66 & 0.00 & 1.8 & 0.075 & 13 & 40 & 0.9978 & 3.51 & 0.56 & 9.4 & 5\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 6 × 12\n",
       "\n",
       "| fixed.acidity &lt;dbl&gt; | volatile.acidity &lt;dbl&gt; | citric.acid &lt;dbl&gt; | residual.sugar &lt;dbl&gt; | chlorides &lt;dbl&gt; | free.sulfur.dioxide &lt;dbl&gt; | total.sulfur.dioxide &lt;dbl&gt; | density &lt;dbl&gt; | pH &lt;dbl&gt; | sulphates &lt;dbl&gt; | alcohol &lt;dbl&gt; | quality &lt;int&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "|  7.4 | 0.70 | 0.00 | 1.9 | 0.076 | 11 | 34 | 0.9978 | 3.51 | 0.56 | 9.4 | 5 |\n",
       "|  7.8 | 0.88 | 0.00 | 2.6 | 0.098 | 25 | 67 | 0.9968 | 3.20 | 0.68 | 9.8 | 5 |\n",
       "|  7.8 | 0.76 | 0.04 | 2.3 | 0.092 | 15 | 54 | 0.9970 | 3.26 | 0.65 | 9.8 | 5 |\n",
       "| 11.2 | 0.28 | 0.56 | 1.9 | 0.075 | 17 | 60 | 0.9980 | 3.16 | 0.58 | 9.8 | 6 |\n",
       "|  7.4 | 0.70 | 0.00 | 1.9 | 0.076 | 11 | 34 | 0.9978 | 3.51 | 0.56 | 9.4 | 5 |\n",
       "|  7.4 | 0.66 | 0.00 | 1.8 | 0.075 | 13 | 40 | 0.9978 | 3.51 | 0.56 | 9.4 | 5 |\n",
       "\n"
      ],
      "text/plain": [
       "  fixed.acidity volatile.acidity citric.acid residual.sugar chlorides\n",
       "1  7.4          0.70             0.00        1.9            0.076    \n",
       "2  7.8          0.88             0.00        2.6            0.098    \n",
       "3  7.8          0.76             0.04        2.3            0.092    \n",
       "4 11.2          0.28             0.56        1.9            0.075    \n",
       "5  7.4          0.70             0.00        1.9            0.076    \n",
       "6  7.4          0.66             0.00        1.8            0.075    \n",
       "  free.sulfur.dioxide total.sulfur.dioxide density pH   sulphates alcohol\n",
       "1 11                  34                   0.9978  3.51 0.56      9.4    \n",
       "2 25                  67                   0.9968  3.20 0.68      9.8    \n",
       "3 15                  54                   0.9970  3.26 0.65      9.8    \n",
       "4 17                  60                   0.9980  3.16 0.58      9.8    \n",
       "5 11                  34                   0.9978  3.51 0.56      9.4    \n",
       "6 13                  40                   0.9978  3.51 0.56      9.4    \n",
       "  quality\n",
       "1 5      \n",
       "2 5      \n",
       "3 5      \n",
       "4 6      \n",
       "5 5      \n",
       "6 5      "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wine <- read.csv('/dsa/data/all_datasets/wine-quality/winequality-red.csv', sep = \";\")\n",
    "head(wine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if wine quality is less than 6, assign the value \"bad\".\n",
    "# if 6 or greater, assign \"good\". create a new target called\n",
    "# taste\n",
    "wine$taste <- ifelse(wine$quality < 6, 'bad', 'good') \n",
    "\n",
    "# 6 is the most popular value by a lot in this set, so \n",
    "# we are going to assign it a unique value. We will call \n",
    "# this \"normal\" as it is in the middle of the distribution.\n",
    "wine$taste[wine$quality == 6] <- 'normal'\n",
    "\n",
    "# make this target variable categorical\n",
    "wine$taste <- as.factor(wine$taste)\n",
    "\n",
    "# remove the old target, since it is no longer needed\n",
    "wine <- wine[,-12]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1**: Create a training data set and testing data set from the `wine` data frame. Make sure that the rows are randomly selected. The training set should be constructed from 60% of the data; call it `train`. The testing set should be called `test` and should be constructed from the **other** 40% of the data. Be sure to pass `123` as the set.seed() first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for exercise 1 goes here\n",
    "# *****************************\n",
    "\n",
    "set.seed(123)\n",
    "numrow = nrow(wine) \n",
    "train_ind <- sample(seq_len(nrow(wine)), size = as.integer(0.6*numrow))\n",
    "train <- wine[train_ind,]\n",
    "test <- wine[-train_ind,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2**: Create a formula for the prediction task. First predict using all of the variables other than the target. In order to avoid typing out all of the variables, you can use the following notation:\n",
    "\n",
    "```splus\n",
    "target ~ .\n",
    "```\n",
    "\n",
    "The \".\" tells `R` to use all other variables in the dataset (that are not the target) as inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for exercise 2 goes here\n",
    "# *****************************\n",
    "\n",
    "frmla = taste ~ ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 3**: Create a Decision Tree model using the `tree` function. Make sure that you pass the newly created formula as a parameter and specify the training data set. Be sure to name this object something (in the examples, we called it `tr`). Then run a summary on the object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for exercise 3 goes here\n",
    "# *****************************\n",
    "\n",
    "tr <- tree(frmla, data = wine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pay attention to the output of the summary.\n",
    "\n",
    "**Exercise 4**: What is the misclassification error rate of the tree using the **testing** set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Classification tree:\n",
       "tree(formula = frmla, data = wine)\n",
       "Variables actually used in tree construction:\n",
       "[1] \"alcohol\"              \"sulphates\"            \"total.sulfur.dioxide\"\n",
       "Number of terminal nodes:  8 \n",
       "Residual mean deviance:  1.558 = 2479 / 1591 \n",
       "Misclassification error rate: 0.3815 = 610 / 1599 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Code for exercise 4 goes here\n",
    "# *****************************\n",
    "\n",
    "summary(tr)\n",
    "\n",
    "# misclassification error rate of the tree is 0.3815 or 38%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 5**: Now create a Naïve Bayes classifier using the formula and training data. Be sure to name this model something (in the other notebooks, we called it `m`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Naive Bayes Classifier for Discrete Predictors\n",
       "\n",
       "Call:\n",
       "naiveBayes.default(x = X, y = Y, laplace = laplace)\n",
       "\n",
       "A-priori probabilities:\n",
       "Y\n",
       "      bad      good    normal \n",
       "0.4734098 0.1303441 0.3962461 \n",
       "\n",
       "Conditional probabilities:\n",
       "        fixed.acidity\n",
       "Y            [,1]     [,2]\n",
       "  bad    8.191189 1.530286\n",
       "  good   8.928000 2.106771\n",
       "  normal 8.458947 1.834325\n",
       "\n",
       "        volatile.acidity\n",
       "Y             [,1]      [,2]\n",
       "  bad    0.5984141 0.1872713\n",
       "  good   0.4045200 0.1430999\n",
       "  normal 0.4914079 0.1687192\n",
       "\n",
       "        citric.acid\n",
       "Y             [,1]      [,2]\n",
       "  bad    0.2390749 0.1853319\n",
       "  good   0.3744800 0.1905444\n",
       "  normal 0.2882105 0.1950711\n",
       "\n",
       "        residual.sugar\n",
       "Y            [,1]     [,2]\n",
       "  bad    2.512445 1.298201\n",
       "  good   2.676400 1.299699\n",
       "  normal 2.471053 1.327730\n",
       "\n",
       "        chlorides\n",
       "Y              [,1]       [,2]\n",
       "  bad    0.09217401 0.05137602\n",
       "  good   0.07500800 0.02245443\n",
       "  normal 0.08388947 0.03630374\n",
       "\n",
       "        free.sulfur.dioxide\n",
       "Y            [,1]     [,2]\n",
       "  bad    16.43612 10.69295\n",
       "  good   14.34800 10.74075\n",
       "  normal 16.18553 10.24491\n",
       "\n",
       "        total.sulfur.dioxide\n",
       "Y            [,1]     [,2]\n",
       "  bad    53.25881 36.24222\n",
       "  good   36.41600 32.42365\n",
       "  normal 41.64474 25.59287\n",
       "\n",
       "        density\n",
       "Y             [,1]        [,2]\n",
       "  bad    0.9970553 0.001547489\n",
       "  good   0.9960550 0.002203826\n",
       "  normal 0.9966485 0.002043225\n",
       "\n",
       "        pH\n",
       "Y            [,1]      [,2]\n",
       "  bad    3.311057 0.1521247\n",
       "  good   3.286880 0.1573542\n",
       "  normal 3.312395 0.1519801\n",
       "\n",
       "        sulphates\n",
       "Y             [,1]      [,2]\n",
       "  bad    0.6209031 0.1747981\n",
       "  good   0.7485600 0.1372818\n",
       "  normal 0.6681842 0.1439680\n",
       "\n",
       "        alcohol\n",
       "Y             [,1]      [,2]\n",
       "  bad     9.942401 0.7196797\n",
       "  good   11.574133 0.9948421\n",
       "  normal 10.641535 1.0472273\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Code for exercise 5 goes here\n",
    "# *****************************\n",
    "\n",
    "m <- naiveBayes(frmla, data = train)\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 6**: What is the misclassification error rate of the Naïve Bayes classifier using the **testing** set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        \n",
       "         bad good normal\n",
       "  bad    222    8     98\n",
       "  good     7   47     30\n",
       "  normal  61   37    130"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Code for exercise 6 goes here\n",
    "# *****************************\n",
    "\n",
    "table(predict(m, test[,-12]), test[,12])\n",
    "\n",
    "# misclassification error rate of the Naïve Bayes classifier is 204/640 = 32%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at the summary of the tree created in Exercise 3. It shows us the features that it used for the classification task. \n",
    "\n",
    "**Exercise 7**: Create a new formula that predicts `taste` using only the features that the decision tree defined. Be sure to name this formula something different from the old formula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for exercise 7 goes here\n",
    "# *****************************\n",
    "\n",
    "\n",
    "frmla2 = taste ~ alcohol + sulphates + total.sulfur.dioxide\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 8**: Now create a Naïve Bayes classifier using this pruned formula and training data. Be sure to name this model something other than your original Naive Bayes model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Naive Bayes Classifier for Discrete Predictors\n",
       "\n",
       "Call:\n",
       "naiveBayes.default(x = X, y = Y, laplace = laplace)\n",
       "\n",
       "A-priori probabilities:\n",
       "Y\n",
       "      bad      good    normal \n",
       "0.4734098 0.1303441 0.3962461 \n",
       "\n",
       "Conditional probabilities:\n",
       "        alcohol\n",
       "Y             [,1]      [,2]\n",
       "  bad     9.942401 0.7196797\n",
       "  good   11.574133 0.9948421\n",
       "  normal 10.641535 1.0472273\n",
       "\n",
       "        sulphates\n",
       "Y             [,1]      [,2]\n",
       "  bad    0.6209031 0.1747981\n",
       "  good   0.7485600 0.1372818\n",
       "  normal 0.6681842 0.1439680\n",
       "\n",
       "        total.sulfur.dioxide\n",
       "Y            [,1]     [,2]\n",
       "  bad    53.25881 36.24222\n",
       "  good   36.41600 32.42365\n",
       "  normal 41.64474 25.59287\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Code for exercise 8 goes here\n",
    "# *****************************\n",
    "\n",
    "\n",
    "m2 <- naiveBayes(frmla2, data = train)\n",
    "m2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 9**: Does using only these select features create a better model according to the testing data misclassification error rate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        \n",
       "         bad good normal\n",
       "  bad    222    8     98\n",
       "  good     7   47     30\n",
       "  normal  61   37    130"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "        \n",
       "         bad good normal\n",
       "  bad    242   13    119\n",
       "  good     2   20     10\n",
       "  normal  46   59    129"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Code for exercise 9 goes here\n",
    "# *****************************\n",
    "\n",
    "table(predict(m, test[,-12]), test[,12]) # misclassification error rate = 32%\n",
    "\n",
    "table(predict(m2, test[,-c(1,2,3,4,5,6,8,9)]), test[,12]) # misclassification error rate = 30%\n",
    "\n",
    "# Yes using only these select features creates a slightly better model according to the testing data misclassification error rate, but only marginally. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save your noteboot, then `File > Close and Halt`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
